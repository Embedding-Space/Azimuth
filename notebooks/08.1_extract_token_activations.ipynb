{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Extract Token Activations Through Layers\n",
    "\n",
    "**Date:** October 29, 2025\n",
    "\n",
    "**Goal:** Capture per-token, per-layer activations to study how token representations evolve geometrically through the model.\n",
    "\n",
    "**Method:**\n",
    "1. Load one text from Wikipedia Simple dataset (~512 tokens)\n",
    "2. Run through model with `output_hidden_states=True`\n",
    "3. Extract activations at all 36 layers\n",
    "4. Save as [n_layers, n_tokens, hidden_dim] tensor in bfloat16\n",
    "\n",
    "**Output:** `data/results/token_activations_sample.pt` containing:\n",
    "- `activations`: [36, n_tokens, 2560] tensor (bfloat16)\n",
    "- `tokens`: List of token IDs\n",
    "- `text`: Original input text\n",
    "- `metadata`: Model name, sequence length, extraction date\n",
    "\n",
    "**Note:** This is DATA COLLECTION only. Analysis happens in 08.2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Model: Qwen/Qwen3-4B-Instruct-2507\n",
      "  Device: auto\n",
      "  Target tokens: 512\n",
      "  Random seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "DATASET_PATH = '../data/wikipedia_top20_texts.json'\n",
    "OUTPUT_PATH = '../data/results/token_activations_sample.pt'\n",
    "\n",
    "# Model\n",
    "MODEL_NAME = 'Qwen/Qwen3-4B-Instruct-2507'\n",
    "DEVICE = 'auto'  # 'auto', 'cuda', 'mps', or 'cpu'\n",
    "\n",
    "# Sampling\n",
    "RANDOM_SEED = 42  # Fixed seed for reproducibility\n",
    "TARGET_TOKENS = 512  # Desired sequence length (will truncate if longer)\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Model: {MODEL_NAME}\")\n",
    "print(f\"  Device: {DEVICE}\")\n",
    "print(f\"  Target tokens: {TARGET_TOKENS}\")\n",
    "print(f\"  Random seed: {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Load Dataset and Select Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "✓ Loaded 20 text pairs\n",
      "\n",
      "Selected text (first 500 chars):\n",
      "A political party is an organization that coordinates candidates to compete in elections and participate in governance. It is common for the members of a party to hold similar ideas about politics, and parties may promote specific ideological or policy goals.\n",
      "Political parties have become a major part of the politics of almost every country, as modern party organizations developed and spread around the world over the last few centuries. Although some countries have no political parties, this is \n",
      "\n",
      "Text length: 43702 characters\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "with open(DATASET_PATH, 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "print(f\"✓ Loaded {len(dataset)} text pairs\")\n",
    "\n",
    "# Extract all English texts\n",
    "simple_texts = [pair['high_complexity'] for pair in dataset]\n",
    "\n",
    "# Select one at random (fixed seed)\n",
    "random.seed(RANDOM_SEED)\n",
    "selected_text = random.choice(simple_texts)\n",
    "\n",
    "print(f\"\\nSelected text (first 500 chars):\")\n",
    "print(selected_text[:500])\n",
    "print(f\"\\nText length: {len(selected_text)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31d4c50e3bc4caea299a26fdf0e73f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded on device: mps:0\n",
      "✓ Model dtype: torch.bfloat16\n",
      "✓ Number of layers: 36\n",
      "✓ Hidden dimension: 2560\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "print(\"Loading model and tokenizer...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=DEVICE,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "print(f\"✓ Model loaded on device: {model.device}\")\n",
    "print(f\"✓ Model dtype: {model.dtype}\")\n",
    "print(f\"✓ Number of layers: {model.config.num_hidden_layers}\")\n",
    "print(f\"✓ Hidden dimension: {model.config.hidden_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Tokenize and Truncate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing text...\n",
      "✓ Tokenized to 512 tokens\n",
      "  (Truncated from longer text)\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenizing text...\")\n",
    "\n",
    "# Tokenize\n",
    "inputs = tokenizer(\n",
    "    selected_text,\n",
    "    return_tensors='pt',\n",
    "    truncation=True,\n",
    "    max_length=TARGET_TOKENS,\n",
    "    padding=False,\n",
    ")\n",
    "\n",
    "# Move to same device as model\n",
    "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "n_tokens = inputs['input_ids'].shape[1]\n",
    "\n",
    "print(f\"✓ Tokenized to {n_tokens} tokens\")\n",
    "if n_tokens < TARGET_TOKENS:\n",
    "    print(f\"  (Text was shorter than target {TARGET_TOKENS})\")\n",
    "else:\n",
    "    print(f\"  (Truncated from longer text)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Extract Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running forward pass to extract activations...\n",
      "✓ Extracted activations with shape: torch.Size([36, 512, 2560])\n",
      "  [n_layers=36, n_tokens=512, hidden_dim=2560]\n",
      "  Dtype: torch.bfloat16\n",
      "  Device: mps:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Running forward pass to extract activations...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(\n",
    "        **inputs,\n",
    "        output_hidden_states=True,\n",
    "        return_dict=True,\n",
    "    )\n",
    "\n",
    "# Extract hidden states\n",
    "# outputs.hidden_states is a tuple of length (n_layers + 1)\n",
    "# hidden_states[0] is embedding layer, hidden_states[1:] are transformer layers\n",
    "hidden_states = outputs.hidden_states[1:]  # Skip embedding layer\n",
    "\n",
    "# Stack into single tensor: [n_layers, batch_size, seq_len, hidden_dim]\n",
    "# Since batch_size=1, we squeeze it: [n_layers, seq_len, hidden_dim]\n",
    "activations = torch.stack(hidden_states).squeeze(1)\n",
    "\n",
    "print(f\"✓ Extracted activations with shape: {activations.shape}\")\n",
    "print(f\"  [n_layers={activations.shape[0]}, n_tokens={activations.shape[1]}, hidden_dim={activations.shape[2]}]\")\n",
    "print(f\"  Dtype: {activations.dtype}\")\n",
    "print(f\"  Device: {activations.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Save to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving activations to disk...\n",
      "✓ Saved to: ../data/results/token_activations_sample.pt\n",
      "  File size: 90.0 MB\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "print(\"Saving activations to disk...\")\n",
    "\n",
    "# Prepare data structure\n",
    "data = {\n",
    "    'activations': activations.cpu(),  # Move to CPU for storage\n",
    "    'tokens': inputs['input_ids'].cpu().squeeze().tolist(),  # Token IDs as list\n",
    "    'text': selected_text,\n",
    "    'metadata': {\n",
    "        'model': MODEL_NAME,\n",
    "        'n_layers': activations.shape[0],\n",
    "        'n_tokens': activations.shape[1],\n",
    "        'hidden_dim': activations.shape[2],\n",
    "        'dtype': str(activations.dtype),\n",
    "        'extraction_date': datetime.now().isoformat(),\n",
    "        'random_seed': RANDOM_SEED,\n",
    "    }\n",
    "}\n",
    "\n",
    "torch.save(data, OUTPUT_PATH)\n",
    "\n",
    "print(f\"✓ Saved to: {OUTPUT_PATH}\")\n",
    "\n",
    "# Compute file size\n",
    "import os\n",
    "file_size_mb = os.path.getsize(OUTPUT_PATH) / (1024 ** 2)\n",
    "print(f\"  File size: {file_size_mb:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying saved data...\n",
      "✓ Activations shape: torch.Size([36, 512, 2560])\n",
      "✓ Number of tokens: 512\n",
      "✓ Text length: 43702 chars\n",
      "✓ Metadata:\n",
      "    model: Qwen/Qwen3-4B-Instruct-2507\n",
      "    n_layers: 36\n",
      "    n_tokens: 512\n",
      "    hidden_dim: 2560\n",
      "    dtype: torch.bfloat16\n",
      "    extraction_date: 2025-10-29T17:53:58.397520\n",
      "    random_seed: 42\n",
      "\n",
      "======================================================================\n",
      "DATA EXTRACTION COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Verifying saved data...\")\n",
    "\n",
    "# Reload and check\n",
    "loaded = torch.load(OUTPUT_PATH, weights_only=False)\n",
    "\n",
    "print(f\"✓ Activations shape: {loaded['activations'].shape}\")\n",
    "print(f\"✓ Number of tokens: {len(loaded['tokens'])}\")\n",
    "print(f\"✓ Text length: {len(loaded['text'])} chars\")\n",
    "print(f\"✓ Metadata:\")\n",
    "for key, value in loaded['metadata'].items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA EXTRACTION COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
