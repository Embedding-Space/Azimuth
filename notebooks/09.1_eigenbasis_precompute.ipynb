{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenbasis Precomputation\n",
    "\n",
    "**Goal:** Compute and save expensive matrices needed for eigenbasis analysis.\n",
    "\n",
    "**Why separate notebook:** These computations are heavy (minutes to run) but only need to be done **once**. Future analysis notebooks (09.2+) can load the precomputed results instantly.\n",
    "\n",
    "**What we compute:**\n",
    "1. Full eigendecomposition of M (eigenvalues + eigenvectors)\n",
    "2. Token projections onto all 2,560 eigenvectors (spherical coordinates)\n",
    "3. [Future: Add more precomputations as needed]\n",
    "\n",
    "**Output files:**\n",
    "- `data/vectors/eigenbasis_qwen3_4b.pt` - Eigenvalues and eigenvectors\n",
    "- `data/vectors/token_eigenbasis_projections_qwen3_4b.pt` - Full projection matrix\n",
    "\n",
    "**Run time:** ~2-5 minutes on CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Model: Qwen/Qwen3-4B-Instruct-2507\n",
      "  Random seed: 42\n",
      "  Output: ../data/vectors/eigenbasis_qwen3_4b.pt\n",
      "  Output: ../data/vectors/token_eigenbasis_projections_qwen3_4b.pt\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from azimuth.config import RANDOM_SEED\n",
    "\n",
    "# Model\n",
    "MODEL_NAME = 'Qwen/Qwen3-4B-Instruct-2507'\n",
    "\n",
    "# Input paths\n",
    "METRIC_TENSOR_PATH = '../data/vectors/causal_metric_tensor_qwen3_4b.pt'\n",
    "\n",
    "# Output paths\n",
    "EIGENBASIS_PATH = '../data/vectors/eigenbasis_qwen3_4b.pt'\n",
    "PROJECTIONS_PATH = '../data/vectors/token_eigenbasis_projections_qwen3_4b.pt'\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Model: {MODEL_NAME}\")\n",
    "print(f\"  Random seed: {RANDOM_SEED}\")\n",
    "print(f\"  Output: {EIGENBASIS_PATH}\")\n",
    "print(f\"  Output: {PROJECTIONS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Metric Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and metric tensor...\n",
      "\n",
      "Loading model from Qwen/Qwen3-4B-Instruct-2507...\n",
      "  This will take a minute...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f0cfeefc644b62a81abca5fedefbeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading causal metric tensor from ../data/vectors/causal_metric_tensor_qwen3_4b.pt...\n",
      "\n",
      "✓ All data loaded\n",
      "  Vocab size: 151,936\n",
      "  Hidden dim: 2,560\n",
      "  Unembedding matrix shape: torch.Size([151936, 2560])\n",
      "  Metric tensor shape: torch.Size([2560, 2560])\n",
      "  Memory usage: 1.58 GB\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading model and metric tensor...\\n\")\n",
    "\n",
    "# Load model (for unembedding matrix)\n",
    "print(f\"Loading model from {MODEL_NAME}...\")\n",
    "print(\"  This will take a minute...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map='cpu',\n",
    ")\n",
    "\n",
    "# Extract FULL unembedding matrix (all vocab)\n",
    "gamma = model.lm_head.weight.data.to(torch.float32).cpu()  # [vocab_size, hidden_dim]\n",
    "vocab_size, hidden_dim = gamma.shape\n",
    "\n",
    "# Load metric tensor\n",
    "print(f\"\\nLoading causal metric tensor from {METRIC_TENSOR_PATH}...\")\n",
    "metric_data = torch.load(METRIC_TENSOR_PATH, weights_only=False)\n",
    "M = metric_data['M'].to(torch.float32).cpu()  # [hidden_dim, hidden_dim]\n",
    "\n",
    "print(f\"\\n✓ All data loaded\")\n",
    "print(f\"  Vocab size: {vocab_size:,}\")\n",
    "print(f\"  Hidden dim: {hidden_dim:,}\")\n",
    "print(f\"  Unembedding matrix shape: {gamma.shape}\")\n",
    "print(f\"  Metric tensor shape: {M.shape}\")\n",
    "print(f\"  Memory usage: {(gamma.element_size() * gamma.nelement() + M.element_size() * M.nelement()) / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Eigendecomposition of M\n",
    "\n",
    "Compute the full eigendecomposition: M = V Λ V^T\n",
    "\n",
    "- **Eigenvalues (Λ):** Variance along each principal axis\n",
    "- **Eigenvectors (V):** The axes themselves (columns of V)\n",
    "\n",
    "This defines the natural coordinate system for the causal metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPUTING EIGENDECOMPOSITION OF M\n",
      "================================================================================\n",
      "\n",
      "Computing eigenvalues and eigenvectors...\n",
      "  Matrix size: torch.Size([2560, 2560])\n",
      "  This will take 1-2 minutes...\n",
      "\n",
      "✓ Eigendecomposition complete\n",
      "\n",
      "Eigenvalue statistics:\n",
      "  Min: 95.35\n",
      "  Max: 94217.94\n",
      "  Mean: 2713.64\n",
      "  Median: 2498.26\n",
      "\n",
      "Orthonormality check:\n",
      "  Max off-diagonal: 2.74e-06 (should be ~0)\n",
      "  ✓ Eigenvectors are orthonormal\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPUTING EIGENDECOMPOSITION OF M\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nComputing eigenvalues and eigenvectors...\")\n",
    "print(f\"  Matrix size: {M.shape}\")\n",
    "print(f\"  This will take 1-2 minutes...\\n\")\n",
    "\n",
    "# Compute eigendecomposition\n",
    "# eigh returns eigenvalues in ascending order\n",
    "eigenvalues, eigenvectors = torch.linalg.eigh(M)\n",
    "\n",
    "print(f\"✓ Eigendecomposition complete\\n\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"Eigenvalue statistics:\")\n",
    "print(f\"  Min: {eigenvalues.min().item():.2f}\")\n",
    "print(f\"  Max: {eigenvalues.max().item():.2f}\")\n",
    "print(f\"  Mean: {eigenvalues.mean().item():.2f}\")\n",
    "print(f\"  Median: {eigenvalues.median().item():.2f}\")\n",
    "\n",
    "# Verify eigenvectors are orthonormal\n",
    "identity_check = eigenvectors.T @ eigenvectors\n",
    "off_diagonal_max = (identity_check - torch.eye(hidden_dim)).abs().max().item()\n",
    "print(f\"\\nOrthonormality check:\")\n",
    "print(f\"  Max off-diagonal: {off_diagonal_max:.2e} (should be ~0)\")\n",
    "\n",
    "if off_diagonal_max < 1e-5:\n",
    "    print(f\"  ✓ Eigenvectors are orthonormal\")\n",
    "else:\n",
    "    print(f\"  ⚠️  Eigenvectors may have numerical issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Eigenbasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving eigenbasis to ../data/vectors/eigenbasis_qwen3_4b.pt...\n",
      "✓ Saved (26.2 MB)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nSaving eigenbasis to {EIGENBASIS_PATH}...\")\n",
    "\n",
    "Path(EIGENBASIS_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    'eigenvalues': eigenvalues,  # [hidden_dim]\n",
    "    'eigenvectors': eigenvectors,  # [hidden_dim, hidden_dim]\n",
    "    'metadata': {\n",
    "        'model': MODEL_NAME,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'source_metric_tensor': METRIC_TENSOR_PATH,\n",
    "        'computation_date': datetime.now().isoformat(),\n",
    "        'description': 'Eigendecomposition of causal metric tensor M = V Λ V^T',\n",
    "        'note': 'Eigenvalues are in ascending order. Eigenvectors are columns of the matrix.',\n",
    "    }\n",
    "}, EIGENBASIS_PATH)\n",
    "\n",
    "file_size = Path(EIGENBASIS_PATH).stat().st_size / 1e6\n",
    "print(f\"✓ Saved ({file_size:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Token Projections onto Eigenbasis\n",
    "\n",
    "**Compute spherical coordinates for all tokens.**\n",
    "\n",
    "Project each token vector onto all 2,560 eigenvectors:\n",
    "\n",
    "```\n",
    "projections[i, j] = gamma[i] · eigenvectors[:, j]\n",
    "```\n",
    "\n",
    "This gives us the \"coordinates\" of each token in the eigenbasis.\n",
    "\n",
    "**Matrix form:** `projections = gamma @ eigenvectors`\n",
    "\n",
    "**Cost:** 151,936 × 2,560 × 2,560 ≈ 1 trillion FLOPs (takes ~30-60 seconds on CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPUTING TOKEN PROJECTIONS ONTO EIGENBASIS\n",
      "================================================================================\n",
      "\n",
      "Matrix multiplication: gamma @ eigenvectors\n",
      "  gamma shape: torch.Size([151936, 2560])\n",
      "  eigenvectors shape: torch.Size([2560, 2560])\n",
      "  Result shape: [151936, 2560]\n",
      "  Total operations: ~1 trillion FLOPs\n",
      "  Estimated time: 30-60 seconds...\n",
      "\n",
      "✓ Projections computed\n",
      "\n",
      "Projection matrix properties:\n",
      "  Shape: torch.Size([151936, 2560])\n",
      "  Memory: 1.56 GB\n",
      "  Value range: [-0.80, 0.73]\n",
      "  Mean: 0.0001\n",
      "  Std: 0.0217\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPUTING TOKEN PROJECTIONS ONTO EIGENBASIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nMatrix multiplication: gamma @ eigenvectors\")\n",
    "print(f\"  gamma shape: {gamma.shape}\")\n",
    "print(f\"  eigenvectors shape: {eigenvectors.shape}\")\n",
    "print(f\"  Result shape: [{vocab_size}, {hidden_dim}]\")\n",
    "print(f\"  Total operations: ~1 trillion FLOPs\")\n",
    "print(f\"  Estimated time: 30-60 seconds...\\n\")\n",
    "\n",
    "# Compute projections\n",
    "projections = gamma @ eigenvectors\n",
    "\n",
    "print(f\"✓ Projections computed\\n\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"Projection matrix properties:\")\n",
    "print(f\"  Shape: {projections.shape}\")\n",
    "print(f\"  Memory: {projections.element_size() * projections.nelement() / 1e9:.2f} GB\")\n",
    "print(f\"  Value range: [{projections.min().item():.2f}, {projections.max().item():.2f}]\")\n",
    "print(f\"  Mean: {projections.mean().item():.4f}\")\n",
    "print(f\"  Std: {projections.std().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify: Reconstruct Token Norms from Projections\n",
    "\n",
    "The eigenvectors form an orthonormal basis, so:\n",
    "\n",
    "```\n",
    "||token||² = Σ (projection onto eigenvector_i)²\n",
    "```\n",
    "\n",
    "This is a sanity check that our projections are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying projections...\n",
      "\n",
      "Norm reconstruction check:\n",
      "  Max difference: 1.79e-06\n",
      "  Mean difference: 6.27e-07\n",
      "\n",
      "  ✓ Projections are correct!\n",
      "    Norms reconstructed from eigenbasis match original norms.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVerifying projections...\\n\")\n",
    "\n",
    "# Compute norms two ways\n",
    "# Method 1: Direct from gamma\n",
    "norms_direct = torch.norm(gamma, dim=1)\n",
    "\n",
    "# Method 2: From projections (since eigenvectors are orthonormal)\n",
    "norms_from_projections = torch.norm(projections, dim=1)\n",
    "\n",
    "# Compare\n",
    "max_diff = (norms_direct - norms_from_projections).abs().max().item()\n",
    "mean_diff = (norms_direct - norms_from_projections).abs().mean().item()\n",
    "\n",
    "print(f\"Norm reconstruction check:\")\n",
    "print(f\"  Max difference: {max_diff:.2e}\")\n",
    "print(f\"  Mean difference: {mean_diff:.2e}\")\n",
    "\n",
    "if max_diff < 1e-4:\n",
    "    print(f\"\\n  ✓ Projections are correct!\")\n",
    "    print(f\"    Norms reconstructed from eigenbasis match original norms.\")\n",
    "else:\n",
    "    print(f\"\\n  ⚠️  Large discrepancy detected - possible numerical issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Token Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving token projections to ../data/vectors/token_eigenbasis_projections_qwen3_4b.pt...\n",
      "✓ Saved (1.56 GB)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nSaving token projections to {PROJECTIONS_PATH}...\")\n",
    "\n",
    "Path(PROJECTIONS_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    'projections': projections,  # [vocab_size, hidden_dim]\n",
    "    'metadata': {\n",
    "        'model': MODEL_NAME,\n",
    "        'vocab_size': vocab_size,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'eigenbasis_source': EIGENBASIS_PATH,\n",
    "        'computation_date': datetime.now().isoformat(),\n",
    "        'description': 'Token projections onto eigenvectors of causal metric tensor M',\n",
    "        'note': 'projections[i, j] = dot product of token i with eigenvector j',\n",
    "    }\n",
    "}, PROJECTIONS_PATH)\n",
    "\n",
    "file_size = Path(PROJECTIONS_PATH).stat().st_size / 1e9\n",
    "print(f\"✓ Saved ({file_size:.2f} GB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "**What we computed:**\n",
    "\n",
    "1. **Eigendecomposition of M:**\n",
    "   - 2,560 eigenvalues (variance along each principal axis)\n",
    "   - 2,560 eigenvectors (the principal axes themselves)\n",
    "   - Saved to: `data/vectors/eigenbasis_qwen3_4b.pt`\n",
    "\n",
    "2. **Token projections onto eigenbasis:**\n",
    "   - 151,936 tokens × 2,560 eigenvectors = spherical coordinates\n",
    "   - Saved to: `data/vectors/token_eigenbasis_projections_qwen3_4b.pt`\n",
    "\n",
    "**Next notebooks (09.2+) can now:**\n",
    "- Load these precomputed matrices instantly\n",
    "- Analyze token distribution along any eigenvector\n",
    "- Find geometric structure in eigenbasis coordinates\n",
    "- Identify which eigenspaces contain semantic information\n",
    "\n",
    "**Ready for eigenbasis analysis!** 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
