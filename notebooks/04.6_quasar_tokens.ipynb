{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# 04.6 Quasar Tokens: Reference Directions in Semantic Space\n",
    "\n",
    "## The Quasar Hypothesis\n",
    "\n",
    "In astronomy, **quasars** (quasi-stellar radio sources) are extremely luminous distant objects that serve as reference points for mapping cosmic structure. They're bright enough to see from across the universe.\n",
    "\n",
    "**Question:** Do certain tokens act as \"quasars\" in semantic space—bright, distant landmarks we can use as reference directions?\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "The 152,936 tokens in our vocabulary are scattered through 2560-dimensional space. We know they cluster in a shell roughly 50 logometers from the origin (from 04.5b/c). But within that shell:\n",
    "\n",
    "- **Are some tokens anomalously far away?** (Deep space outliers)\n",
    "- **Do special tokens (like `<|endoftext|>`) have distinctive positions?**\n",
    "- **Can we use these as reference directions** for navigation and measurement?\n",
    "\n",
    "Even with just ONE reference direction, we can:\n",
    "- Measure **polarity** (alignment/projection of other tokens)\n",
    "- Define semantic axes (\"toward the quasar\" vs \"away from the quasar\")\n",
    "- Detect **off-manifold drift** during steering (are we heading toward empty space?)\n",
    "- Characterize **special tokens** as a distinct geometric class\n",
    "\n",
    "---\n",
    "\n",
    "## Planned Experiments\n",
    "\n",
    "This notebook series will explore quasar candidates and their geometric properties.\n",
    "\n",
    "### 04.6a: Finding Quasar Candidates in Deep Space\n",
    "\n",
    "**Goal:** Identify the most distant tokens in causal space.\n",
    "\n",
    "**Method:**\n",
    "1. Compute causal norms ||γᵢ||_M for all 152,936 tokens\n",
    "2. Sort by causal norm (descending)\n",
    "3. Report top 10 most distant tokens\n",
    "4. Decode token IDs to see what they are\n",
    "5. Check if special tokens (`<|endoftext|>`, `<|im_start|>`, etc.) appear in the list\n",
    "\n",
    "**Hypothesis:** Special control tokens might be geometric outliers—far from the main token cluster.\n",
    "\n",
    "**If this flunks:** Try tokens *closest* to origin instead (though these might just be rare/unused tokens).\n",
    "\n",
    "### 04.6b: Measuring Polarity and Alignment\n",
    "\n",
    "**Goal:** Use the most distant token as a reference direction.\n",
    "\n",
    "**Method:**\n",
    "1. Pick the #1 most distant token as our \"quasar\"\n",
    "2. For all other tokens, compute:\n",
    "   - **Alignment:** cos(θ) between token and quasar (Euclidean and causal)\n",
    "   - **Projection:** component along quasar direction\n",
    "   - **Orthogonal component:** what's left after removing quasar projection\n",
    "3. Visualize distribution of alignments\n",
    "4. Find tokens most/least aligned with the quasar\n",
    "\n",
    "**Questions:**\n",
    "- Are tokens randomly oriented relative to the quasar?\n",
    "- Or is there systematic structure (clustering at certain angles)?\n",
    "\n",
    "### 04.6c: Special Token Constellation\n",
    "\n",
    "**Goal:** Map the geometric relationships between special tokens.\n",
    "\n",
    "**Method:**\n",
    "1. Identify all special tokens in vocabulary:\n",
    "   - `<|endoftext|>`, `<|im_start|>`, `<|im_end|>`\n",
    "   - `<|system|>`, `<|user|>`, `<|assistant|>`\n",
    "   - Any other structural markers\n",
    "2. Compute pairwise causal distances between them\n",
    "3. Check their causal norms (are they outliers?)\n",
    "4. Find their k-nearest neighbors in the full token set\n",
    "\n",
    "**Questions:**\n",
    "- Do special tokens form their own cluster?\n",
    "- Are they scattered throughout semantic space?\n",
    "- What \"normal\" tokens are nearest to special tokens?\n",
    "\n",
    "### 04.6d: Distance from Quasar as a Semantic Axis\n",
    "\n",
    "**Goal:** Use distance-from-quasar as a semantic coordinate.\n",
    "\n",
    "**Method:**\n",
    "1. For all tokens, compute d(token, quasar) in logometers\n",
    "2. Bin tokens by distance (near/medium/far from quasar)\n",
    "3. Sample tokens from each bin and examine them qualitatively\n",
    "4. Look for semantic patterns (e.g., are content words far? Function words near?)\n",
    "\n",
    "**Questions:**\n",
    "- Does \"distance from quasar\" correlate with any semantic property?\n",
    "- Can we use it as a meaningful coordinate axis?\n",
    "\n",
    "### 04.6e: Steering Navigation with Quasar Reference\n",
    "\n",
    "**Goal:** Use the quasar to detect off-manifold drift during steering.\n",
    "\n",
    "**Method:**\n",
    "1. Load a steering vector (e.g., complexity vector from 02)\n",
    "2. Simulate steering: h' = h + α·v for various α\n",
    "3. At each steering coefficient, measure:\n",
    "   - Distance from quasar: d(h', quasar)\n",
    "   - Alignment with quasar: cos(θ) between h' and quasar\n",
    "   - Nearest token distance: min(d(h', γᵢ)) for all tokens\n",
    "4. Plot these metrics vs steering coefficient α\n",
    "\n",
    "**Hypothesis:** As we go off-manifold (large α), we might drift toward/away from the quasar in systematic ways.\n",
    "\n",
    "**Application:** Could use \"heading toward quasar\" as a warning sign of off-manifold drift.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Start with Distance?\n",
    "\n",
    "We're looking for quasar *candidates* first—tokens that are geometrically exceptional. The most distant tokens are natural candidates because:\n",
    "\n",
    "1. **They're outliers** by definition (far from typical ~50 logometer shell)\n",
    "2. **They're visible from everywhere** (high norm = \"bright\" in our analogy)\n",
    "3. **They might be structurally important** (control tokens, boundaries, null states)\n",
    "\n",
    "From 04.1, we know the token cloud has a diameter of ~112 logometers. If typical tokens sit at radius ~50, then the most distant tokens are at **~56+ logometers**—significantly beyond the main cluster.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup and Shared Code\n",
    "\n",
    "The cells below load the model, tokenizer, and metric tensor. Each experiment notebook (04.6a, 04.6b, etc.) will replicate this setup in its own config cell—no cross-notebook dependencies.\n",
    "\n",
    "If we end up reusing this code a lot, we'll extract it to `azimuth/quasars.py` following the project philosophy: \"write it twice in notebooks, then it belongs in the package.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Model and paths\n",
    "MODEL_NAME = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "METRIC_PATH = Path(\"../data/vectors/causal_metric_tensor_qwen3_4b.pt\")\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-header",
   "metadata": {},
   "source": [
    "## Load Model, Tokenizer, and Metric Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-metric",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metric tensor\n",
    "print(\"Loading causal metric tensor...\")\n",
    "metric_data = torch.load(METRIC_PATH, map_location=device, weights_only=True)\n",
    "M = metric_data['M']\n",
    "print(f\"M shape: {M.shape}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model for gamma matrix\n",
    "print(f\"Loading {MODEL_NAME}...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "# Extract gamma (unembedding matrix)\n",
    "gamma = model.lm_head.weight.data.to(dtype=torch.float32, device=device)\n",
    "vocab_size, hidden_dim = gamma.shape\n",
    "print(f\"Gamma shape: {gamma.shape}\")\n",
    "print(f\"Vocabulary size: {vocab_size:,} tokens\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-tokenizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer for decoding\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "print(\"Tokenizer loaded.\")\n",
    "print(f\"Vocab size from tokenizer: {len(tokenizer):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify-header",
   "metadata": {},
   "source": [
    "## Quick Verification: Find a Known Special Token\n",
    "\n",
    "Let's verify we can decode token IDs correctly by finding `<|endoftext|>` or similar special tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for common special tokens\n",
    "special_token_names = [\n",
    "    '<|endoftext|>',\n",
    "    '<|im_start|>',\n",
    "    '<|im_end|>',\n",
    "    '<|system|>',\n",
    "    '<|user|>',\n",
    "    '<|assistant|>',\n",
    "]\n",
    "\n",
    "print(\"Looking for special tokens in vocabulary:\")\n",
    "print(\"=\"*60)\n",
    "for token_str in special_token_names:\n",
    "    try:\n",
    "        # Encode the string (might return multiple tokens)\n",
    "        token_ids = tokenizer.encode(token_str, add_special_tokens=False)\n",
    "        if len(token_ids) == 1:\n",
    "            token_id = token_ids[0]\n",
    "            decoded = tokenizer.decode([token_id])\n",
    "            print(f\"Found: '{decoded}' (ID: {token_id})\")\n",
    "        else:\n",
    "            print(f\"'{token_str}' → {len(token_ids)} tokens (not a single token)\")\n",
    "    except Exception as e:\n",
    "        print(f\"'{token_str}' → Error: {e}\")\n",
    "\n",
    "print(\"\\nNote: Some models use different special token syntax.\")\n",
    "print(\"We'll identify actual quasar candidates by distance in 04.6a.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "This notebook establishes the framework. Continue to:\n",
    "\n",
    "- **04.6a:** Find the most distant tokens in causal space (quasar candidates)\n",
    "- **04.6b:** Measure polarity and alignment using the quasar as reference\n",
    "- **04.6c:** Map relationships between special tokens\n",
    "- **04.6d:** Use distance-from-quasar as a semantic coordinate\n",
    "- **04.6e:** Apply quasar reference to steering navigation\n",
    "\n",
    "Each experiment is self-contained and can be run independently."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
