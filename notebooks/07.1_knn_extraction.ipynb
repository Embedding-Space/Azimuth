{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairwise Distance Matrix Extraction (Causal Metric)\n",
    "\n",
    "Compute pairwise causal distances for a random sample of tokens.\n",
    "\n",
    "**Why this approach:**\n",
    "- Configurable sample size N (tune for your time/memory budget)\n",
    "- Full NÃ—N distance matrix stored once, reused forever for UMAP experiments\n",
    "- Upper-triangle compression saves 50% storage\n",
    "- fp16 precision: 15Ã— faster via tensor cores, adequate precision for visualization\n",
    "\n",
    "**Method:**\n",
    "1. Load unembedding matrix Î³ and metric tensor M\n",
    "2. Randomly sample N tokens from vocabulary\n",
    "3. Compute full NÃ—N pairwise causal distances using fp16\n",
    "4. Save upper triangle (symmetric matrix)\n",
    "\n",
    "**Expected runtime (H100):**\n",
    "- N=16,000: ~2-3 minutes\n",
    "- N=50,000: ~15-20 minutes\n",
    "- N=152,936 (full vocab): ~2-3 hours\n",
    "\n",
    "**Output size:**\n",
    "- N=16,000: ~256 MB (upper triangle)\n",
    "- N=50,000: ~2.5 GB\n",
    "- N=152,936: ~23 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Sample size: 64,000 tokens\n",
      "  Precision: float16\n",
      "  Batch sizes: 500 Ã— 10000\n",
      "  Expected memory: ~25.6 GB peak\n",
      "  Expected output: ~4.10 GB (upper triangle)\n"
     ]
    }
   ],
   "source": [
    "# Sample size: tune this to fit your time/memory budget\n",
    "N_TOKENS = 64000  # Start here, scale up to 50k or 152k\n",
    "\n",
    "# Model configuration\n",
    "MODEL_NAME = 'Qwen/Qwen3-4B-Instruct-2507'\n",
    "DEVICE = 'cuda'  # 'cuda' for cloud GPU, 'mps' for Mac, 'cpu' for fallback\n",
    "\n",
    "# Precision (use fp16 for speed via tensor cores)\n",
    "DTYPE = 'float16'  # 'float16' or 'float32'\n",
    "\n",
    "# Batching (tuned for H100 80GB VRAM)\n",
    "BATCH_SIZE_I = 500   # Query batch size\n",
    "BATCH_SIZE_J = 10000 # Target batch size\n",
    "# Memory: 500 Ã— 10,000 Ã— 2560 Ã— 2 bytes â‰ˆ 25 GB (safe)\n",
    "\n",
    "# Input paths\n",
    "METRIC_TENSOR_PATH = '../data/vectors/causal_metric_tensor_qwen3_4b.pt'\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_DISTANCES = f'../data/vectors/distances_causal_{N_TOKENS}.pt'\n",
    "\n",
    "# Random seed\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Sample size: {N_TOKENS:,} tokens\")\n",
    "print(f\"  Precision: {DTYPE}\")\n",
    "print(f\"  Batch sizes: {BATCH_SIZE_I} Ã— {BATCH_SIZE_J}\")\n",
    "print(f\"  Expected memory: ~{BATCH_SIZE_I * BATCH_SIZE_J * 2560 * (2 if DTYPE == 'float16' else 4) / 1e9:.1f} GB peak\")\n",
    "print(f\"  Expected output: ~{N_TOKENS * (N_TOKENS - 1) // 2 * (2 if DTYPE == 'float16' else 4) / 1e9:.2f} GB (upper triangle)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Using device: cuda\n",
      "âœ“ Using dtype: torch.float16\n",
      "  GPU: NVIDIA H200\n",
      "  VRAM: 150.1 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = torch.device(DEVICE)\n",
    "dtype = torch.float16 if DTYPE == 'float16' else torch.float32\n",
    "\n",
    "print(f\"âœ“ Using device: {device}\")\n",
    "print(f\"âœ“ Using dtype: {dtype}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Unembedding Matrix (Î³)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model to extract unembedding matrix...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df793ad13b848cf9b208ce9027b7896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Extracted unembedding matrix\n",
      "  Vocabulary size: 151,936\n",
      "  Hidden dim: 2,560\n",
      "  Memory: 0.78 GB\n",
      "âœ“ Freed model memory\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading model to extract unembedding matrix...\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=dtype,\n",
    "    device_map=device,\n",
    ")\n",
    "\n",
    "# Extract unembedding matrix Î³\n",
    "gamma = model.lm_head.weight.data.clone()  # [vocab_size, hidden_dim]\n",
    "vocab_size, hidden_dim = gamma.shape\n",
    "\n",
    "print(f\"âœ“ Extracted unembedding matrix\")\n",
    "print(f\"  Vocabulary size: {vocab_size:,}\")\n",
    "print(f\"  Hidden dim: {hidden_dim:,}\")\n",
    "print(f\"  Memory: {gamma.element_size() * gamma.nelement() / 1e9:.2f} GB\")\n",
    "\n",
    "# Free model memory\n",
    "del model\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "print(f\"âœ“ Freed model memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Causal Metric Tensor (M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading causal metric tensor from ../data/vectors/causal_metric_tensor_qwen3_4b.pt...\n",
      "âœ“ Loaded metric tensor\n",
      "  Shape: torch.Size([2560, 2560])\n",
      "  Dtype: torch.float16\n",
      "  Memory: 13.1 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading causal metric tensor from {METRIC_TENSOR_PATH}...\")\n",
    "metric_data = torch.load(METRIC_TENSOR_PATH, map_location=device, weights_only=False)\n",
    "\n",
    "M = metric_data['M'].to(dtype=dtype)  # [hidden_dim, hidden_dim]\n",
    "\n",
    "print(f\"âœ“ Loaded metric tensor\")\n",
    "print(f\"  Shape: {M.shape}\")\n",
    "print(f\"  Dtype: {M.dtype}\")\n",
    "print(f\"  Memory: {M.element_size() * M.nelement() / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample N Tokens Randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 64,000 random tokens...\n",
      "(Random sampling avoids vocabulary ordering bias)\n",
      "âœ“ Sampled embeddings shape: torch.Size([64000, 2560])\n",
      "  Memory: 327.7 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nSampling {N_TOKENS:,} random tokens...\")\n",
    "print(\"(Random sampling avoids vocabulary ordering bias)\")\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "sample_indices = torch.randperm(vocab_size)[:N_TOKENS].to(device)\n",
    "sample_embeddings = gamma[sample_indices]  # [N_TOKENS, hidden_dim]\n",
    "\n",
    "print(f\"âœ“ Sampled embeddings shape: {sample_embeddings.shape}\")\n",
    "print(f\"  Memory: {sample_embeddings.element_size() * sample_embeddings.nelement() / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Pairwise Distances\n",
    "\n",
    "Uses batched computation optimized for tensor cores:\n",
    "- Broadcasts to [batch_i, batch_j, hidden_dim] tensors\n",
    "- Matmul with M: ~6.5 billion ops per batch (excellent for tensor cores)\n",
    "- Memory-safe batching: ~25 GB peak on H100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing pairwise distance matrix...\n",
      "  This will compute 4,096,000,000 distances\n",
      "  Estimated time: 32.0 minutes on H100\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5a4440145a46c081654ac9ececeb71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing distances:   0%|          | 0/896 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Distance matrix computed!\n",
      "  Shape: torch.Size([64000, 64000])\n",
      "  Memory: 8.19 GB\n"
     ]
    }
   ],
   "source": [
    "def compute_pairwise_distances(embeddings, M, batch_i=500, batch_j=10000):\n",
    "    \"\"\"\n",
    "    Compute full pairwise causal distance matrix.\n",
    "    \n",
    "    Distance formula: d(i,j) = sqrt((Î³_i - Î³_j)^T M (Î³_i - Î³_j))\n",
    "    \n",
    "    Args:\n",
    "        embeddings: [N, hidden_dim] - Token embeddings\n",
    "        M: [hidden_dim, hidden_dim] - Causal metric tensor\n",
    "        batch_i: Query batch size\n",
    "        batch_j: Target batch size\n",
    "    \n",
    "    Returns:\n",
    "        distances: [N, N] - Pairwise causal distances\n",
    "    \"\"\"\n",
    "    N = embeddings.shape[0]\n",
    "    distances = torch.zeros(N, N, dtype=embeddings.dtype, device=embeddings.device)\n",
    "    \n",
    "    n_batches_i = int(np.ceil(N / batch_i))\n",
    "    n_batches_j = int(np.ceil(N / batch_j))\n",
    "    total_batches = n_batches_i * n_batches_j\n",
    "    \n",
    "    with tqdm(total=total_batches, desc=\"Computing distances\") as pbar:\n",
    "        for i in range(0, N, batch_i):\n",
    "            i_end = min(i + batch_i, N)\n",
    "            tokens_i = embeddings[i:i_end]  # [batch_i, hidden_dim]\n",
    "            \n",
    "            for j in range(0, N, batch_j):\n",
    "                j_end = min(j + batch_j, N)\n",
    "                tokens_j = embeddings[j:j_end]  # [batch_j, hidden_dim]\n",
    "                \n",
    "                # Broadcasting: [batch_i, 1, hidden_dim] - [1, batch_j, hidden_dim]\n",
    "                diff = tokens_i[:, None, :] - tokens_j[None, :, :]  # [batch_i, batch_j, hidden_dim]\n",
    "                \n",
    "                # Matmul with metric tensor (tensor cores activate here!)\n",
    "                # einsum handles the batch dimensions automatically\n",
    "                M_delta = torch.einsum('ijk,kl->ijl', diff, M)  # [batch_i, batch_j, hidden_dim]\n",
    "                \n",
    "                # Inner product and sqrt\n",
    "                squared_dist = (diff * M_delta).sum(dim=-1)  # [batch_i, batch_j]\n",
    "                distances[i:i_end, j:j_end] = torch.sqrt(torch.clamp(squared_dist, min=0))\n",
    "                \n",
    "                pbar.update(1)\n",
    "    \n",
    "    return distances\n",
    "\n",
    "print(\"\\nComputing pairwise distance matrix...\")\n",
    "print(f\"  This will compute {N_TOKENS * N_TOKENS:,} distances\")\n",
    "print(f\"  Estimated time: {N_TOKENS**2 / 16000**2 * 2:.1f} minutes on H100\\n\")\n",
    "\n",
    "distances = compute_pairwise_distances(sample_embeddings, M, BATCH_SIZE_I, BATCH_SIZE_J)\n",
    "\n",
    "print(f\"\\nâœ“ Distance matrix computed!\")\n",
    "print(f\"  Shape: {distances.shape}\")\n",
    "print(f\"  Memory: {distances.element_size() * distances.nelement() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation checks:\n",
      "  Self-distances (diagonal, should be ~0):\n",
      "    Mean: 0.000000\n",
      "    Max: 0.000000\n",
      "  Symmetry check (should be ~0): 0.000000\n",
      "  Minimum distance (should be â‰¥0): 0.000000\n",
      "\n",
      "Distance statistics (excluding diagonal):\n",
      "  Min: 0.00\n",
      "  Max: 112.69\n",
      "  Mean: 71.00\n",
      "  Median (approx, n=100,000,000): 72.19\n",
      "  Std: 8.03\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nValidation checks:\")\n",
    "\n",
    "# Check 1: Diagonal should be zero (self-distances)\n",
    "diag = torch.diagonal(distances)\n",
    "print(f\"  Self-distances (diagonal, should be ~0):\")\n",
    "print(f\"    Mean: {diag.mean().item():.6f}\")\n",
    "print(f\"    Max: {diag.max().item():.6f}\")\n",
    "\n",
    "# Check 2: Matrix should be symmetric\n",
    "asymmetry = (distances - distances.T).abs().max()\n",
    "print(f\"  Symmetry check (should be ~0): {asymmetry.item():.6f}\")\n",
    "\n",
    "# Check 3: All distances should be non-negative\n",
    "min_dist = distances.min()\n",
    "print(f\"  Minimum distance (should be â‰¥0): {min_dist.item():.6f}\")\n",
    "\n",
    "# Distance statistics\n",
    "# Exclude diagonal for statistics\n",
    "mask = ~torch.eye(N_TOKENS, dtype=torch.bool, device=distances.device)\n",
    "off_diag = distances[mask]\n",
    "\n",
    "print(f\"\\nDistance statistics (excluding diagonal):\")\n",
    "print(f\"  Min: {off_diag.min().item():.2f}\")\n",
    "print(f\"  Max: {off_diag.max().item():.2f}\")\n",
    "print(f\"  Mean: {off_diag.mean().item():.2f}\")\n",
    "\n",
    "# Median computation - handle INT_MAX limitation for large arrays\n",
    "if off_diag.numel() < 2_000_000_000:  # Safe threshold below INT_MAX\n",
    "    median_val = off_diag.median().item()\n",
    "    print(f\"  Median: {median_val:.2f}\")\n",
    "else:\n",
    "    # Array too large - use reservoir sampling for median approximation\n",
    "    sample_size = 100_000_000  # 100M samples\n",
    "    # Use random integers directly (no sorting required)\n",
    "    sample_indices = torch.randint(0, off_diag.numel(), (sample_size,), device=off_diag.device)\n",
    "    median_val = off_diag[sample_indices].median().item()\n",
    "    print(f\"  Median (approx, n={sample_size:,}): {median_val:.2f}\")\n",
    "\n",
    "print(f\"  Std: {off_diag.std().item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Distance Matrix (Upper Triangle)\n",
    "\n",
    "Since the matrix is symmetric, we only need to store the upper triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting upper triangle...\n",
      "âœ“ Upper triangle extracted\n",
      "  Values: 2,047,968,000\n",
      "  Memory: 4.10 GB\n",
      "\n",
      "Saving to ../data/vectors/distances_causal_64000.pt...\n",
      "âœ“ Saved!\n",
      "  File size: 4.90 GB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nExtracting upper triangle...\")\n",
    "\n",
    "# Get upper triangle indices (excluding diagonal)\n",
    "triu_indices = torch.triu_indices(N_TOKENS, N_TOKENS, offset=1, device=device)\n",
    "triu_values = distances[triu_indices[0], triu_indices[1]]\n",
    "\n",
    "print(f\"âœ“ Upper triangle extracted\")\n",
    "print(f\"  Values: {triu_values.shape[0]:,}\")\n",
    "print(f\"  Memory: {triu_values.element_size() * triu_values.nelement() / 1e9:.2f} GB\")\n",
    "\n",
    "# Save\n",
    "print(f\"\\nSaving to {OUTPUT_DISTANCES}...\")\n",
    "torch.save({\n",
    "    'triu_values': triu_values.cpu(),\n",
    "    'token_indices': sample_indices.cpu(),\n",
    "    'N': N_TOKENS,\n",
    "    'metadata': {\n",
    "        'model': MODEL_NAME,\n",
    "        'metric_tensor_path': METRIC_TENSOR_PATH,\n",
    "        'vocab_size': vocab_size,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dtype': str(dtype),\n",
    "        'random_seed': RANDOM_SEED,\n",
    "        'distance_stats': {\n",
    "            'min': off_diag.min().item(),\n",
    "            'max': off_diag.max().item(),\n",
    "            'mean': off_diag.mean().item(),\n",
    "            'median': median_val,  # Use pre-computed median from validation cell\n",
    "            'std': off_diag.std().item(),\n",
    "        },\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "    }\n",
    "}, OUTPUT_DISTANCES)\n",
    "\n",
    "import os\n",
    "file_size = os.path.getsize(OUTPUT_DISTANCES) / 1e9\n",
    "print(f\"âœ“ Saved!\")\n",
    "print(f\"  File size: {file_size:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## How to Load and Reconstruct\n",
    "\n",
    "```python\n",
    "# Load\n",
    "data = torch.load('distances_causal_16000.pt')\n",
    "triu_values = data['triu_values']\n",
    "token_indices = data['token_indices']\n",
    "N = data['N']\n",
    "\n",
    "# Reconstruct full symmetric matrix\n",
    "distances = torch.zeros(N, N, dtype=triu_values.dtype)\n",
    "triu_indices = torch.triu_indices(N, N, offset=1)\n",
    "distances[triu_indices[0], triu_indices[1]] = triu_values\n",
    "distances = distances + distances.T  # Make symmetric\n",
    "\n",
    "# Now run UMAP with different hyperparameters\n",
    "from umap import UMAP\n",
    "\n",
    "umap_2d = UMAP(n_components=2, metric='precomputed', n_neighbors=15, min_dist=0.1)\n",
    "embedding_2d = umap_2d.fit_transform(distances.numpy())\n",
    "\n",
    "umap_3d = UMAP(n_components=3, metric='precomputed', n_neighbors=50, min_dist=0.01)\n",
    "embedding_3d = umap_3d.fit_transform(distances.numpy())\n",
    "\n",
    "# etc.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "âœ“ Computed pairwise causal distances for {N_TOKENS:,} tokens\n",
    "\n",
    "âœ“ Saved upper triangle (symmetric matrix compression)\n",
    "\n",
    "**Next steps:**\n",
    "1. Download the `.pt` file to your local machine\n",
    "2. Load and reconstruct the full distance matrix\n",
    "3. Run UMAP with different hyperparameters (n_neighbors, min_dist, n_components)\n",
    "4. Visualize semantic space! ðŸŒŒ\n",
    "\n",
    "**To scale up:**\n",
    "- Increase N_TOKENS to 50,000 or 152,936 (full vocab)\n",
    "- Rent more VRAM if needed (H200 has 141 GB)\n",
    "- Same code works at any scale!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
